{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2114ce97",
   "metadata": {},
   "source": [
    "# Support Vector Machine for Vegetation Change Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99051d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38ae59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score, jaccard_score\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from image_preprocessing.image_preprocessing import load_image_pairs_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a113b7",
   "metadata": {},
   "source": [
    "### Create Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625bafb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../../Data/Antwerpen/Antwerpen_2018/JPEG2000/OMWRGB18VL_11002.jp2 into shape (3, 8500, 7000)\n",
      "Reading ../../Data/Antwerpen/Antwerpen_2022/JPEG2000/OMWRGB22VL_11002.jp2 into shape (3, 8500, 7000)\n"
     ]
    }
   ],
   "source": [
    "image_paths_train = [\n",
    "    ('../../Data/Antwerpen/Antwerpen_2018/JPEG2000/OMWRGB18VL_11002.jp2', '../../Data/Antwerpen/Antwerpen_2022/JPEG2000/OMWRGB22VL_11002.jp2', 8500, 7000, 4420, 6980, 3320, 5880, 256),\n",
    "    # ('../../Data/Leuven/Leuven_2018/JPEG2000/OMWRGB18VL_24062.jp2', '../../Data/Leuven/Leuven_2022/JPEG2000/OMWRGB22VL_24062.jp2', 8500, 7000, 3620, 6180, 2320, 4880, 256),\n",
    "    # ('../../Data/Kortrijk/Kortrijk_2018/JPEG2000/OMWRGB18VL_34022.jp2', '../../Data/Kortrijk/Kortrijk_2022/JPEG2000/OMWRGB22VL_34022.jp2', 8500, 7000, 2120, 4680, 1520, 4080, 256),\n",
    "    # ('../../Data/Brugge/Brugge_2018/JPEG2000/OMWRGB18VL_31005.jp2', '../../Data/Brugge/Brugge_2022/JPEG2000/OMWRGB22VL_31005.jp2', 8000, 6500, 4470, 7030, 2020, 4580, 256),\n",
    "    # ('../../Data/Hasselt/Hasselt_2018/JPEG2000/OMWRGB18VL_71022.jp2', '../../Data/Hasselt/Hasselt_2022/JPEG2000/OMWRGB22VL_71022.jp2', 8500, 7000, 2570, 5130, 3020, 5580, 256),\n",
    "    # ('../../Data/Mechelen/Mechelen_2018/JPEG2000/OMWRGB18VL_12025.jp2', '../../Data/Mechelen/Mechelen_2022/JPEG2000/OMWRGB22VL_12025.jp2', 8500, 7000, 3570, 6130, 3020, 5580, 256),\n",
    "               ]\n",
    "\n",
    "image_pairs_train, labels_train = load_image_pairs_labels(image_paths_train)\n",
    "\n",
    "# cleanup\n",
    "if 255 in np.unique(labels_train):\n",
    "   labels_train = np.clip(labels_train, 0, 1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08df0ec",
   "metadata": {},
   "source": [
    "### Creating Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e964b7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../../Data/Gent/Gent_2020/JPEG2000/OMWRGB20VL_44021.jp2 into shape (3, 8500, 7000)\n",
      "Reading ../../Data/Gent/Gent_2024/JPEG2000/OMWRGB24VL_44021.jp2 into shape (3, 8500, 7000)\n"
     ]
    }
   ],
   "source": [
    "image_paths_test = [\n",
    "    ('../../Data/Gent/Gent_2020/JPEG2000/OMWRGB20VL_44021.jp2', '../../Data/Gent/Gent_2024/JPEG2000/OMWRGB24VL_44021.jp2', 8500, 7000, 4220, 6780, 2520, 5080, 256)\n",
    "               ]\n",
    "\n",
    "image_pairs_test, labels_test = load_image_pairs_labels(image_paths_test)\n",
    "\n",
    "# cleanup\n",
    "if 255 in np.unique(labels_test):\n",
    "   labels_test = np.clip(labels_test, 0, 1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e6959",
   "metadata": {},
   "source": [
    "### Prepare SVM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32c38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_svm_data(before_img, after_image, change_mask):\n",
    "    \"\"\"\n",
    "    Prepare features and labels from two RGB images and a change mask.\n",
    "    - before_img, after_img: shape (H, W, 3)\n",
    "    - change_mask: shape (H, W), binary 0/1\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    # Feature vectors: concat or diff\n",
    "    features = np.concatenate([before_img, after_image, np.abs(before_img - after_image)], axis=-1)  # shape (H, W, 9)\n",
    "    X = features.reshape(-1, 9)\n",
    "    y = change_mask.reshape(-1).astype(np.uint8)\n",
    "    \n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1755ff55",
   "metadata": {},
   "source": [
    "### Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d20d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained on image pair:  1\n",
      "model trained on image pair:  2\n",
      "model trained on image pair:  3\n",
      "model trained on image pair:  4\n",
      "model trained on image pair:  5\n",
      "model trained on image pair:  6\n",
      "model trained on image pair:  7\n",
      "model trained on image pair:  8\n",
      "model trained on image pair:  9\n",
      "model trained on image pair:  10\n",
      "model trained on image pair:  11\n",
      "model trained on image pair:  12\n",
      "model trained on image pair:  13\n",
      "model trained on image pair:  14\n",
      "model trained on image pair:  15\n",
      "model trained on image pair:  16\n",
      "model trained on image pair:  17\n",
      "model trained on image pair:  18\n",
      "model trained on image pair:  19\n",
      "model trained on image pair:  20\n",
      "model trained on image pair:  21\n",
      "model trained on image pair:  22\n",
      "model trained on image pair:  23\n",
      "model trained on image pair:  24\n",
      "model trained on image pair:  25\n",
      "model trained on image pair:  26\n",
      "model trained on image pair:  27\n",
      "model trained on image pair:  28\n",
      "model trained on image pair:  29\n",
      "model trained on image pair:  30\n",
      "model trained on image pair:  31\n",
      "model trained on image pair:  32\n",
      "model trained on image pair:  33\n",
      "model trained on image pair:  34\n",
      "model trained on image pair:  35\n",
      "model trained on image pair:  36\n",
      "model trained on image pair:  37\n",
      "model trained on image pair:  38\n",
      "model trained on image pair:  39\n",
      "model trained on image pair:  40\n",
      "model trained on image pair:  41\n",
      "model trained on image pair:  42\n",
      "model trained on image pair:  43\n",
      "model trained on image pair:  44\n",
      "model trained on image pair:  45\n",
      "model trained on image pair:  46\n",
      "model trained on image pair:  47\n",
      "model trained on image pair:  48\n",
      "model trained on image pair:  49\n",
      "model trained on image pair:  50\n",
      "model trained on image pair:  51\n",
      "model trained on image pair:  52\n",
      "model trained on image pair:  53\n",
      "model trained on image pair:  54\n",
      "model trained on image pair:  55\n",
      "model trained on image pair:  56\n",
      "model trained on image pair:  57\n",
      "model trained on image pair:  58\n",
      "model trained on image pair:  59\n",
      "model trained on image pair:  60\n",
      "model trained on image pair:  61\n",
      "model trained on image pair:  62\n",
      "model trained on image pair:  63\n",
      "model trained on image pair:  64\n",
      "model trained on image pair:  65\n",
      "model trained on image pair:  66\n",
      "model trained on image pair:  67\n",
      "model trained on image pair:  68\n",
      "model trained on image pair:  69\n",
      "model trained on image pair:  70\n",
      "model trained on image pair:  71\n",
      "model trained on image pair:  72\n",
      "model trained on image pair:  73\n",
      "model trained on image pair:  74\n",
      "model trained on image pair:  75\n",
      "model trained on image pair:  76\n",
      "model trained on image pair:  77\n",
      "model trained on image pair:  78\n",
      "model trained on image pair:  79\n",
      "model trained on image pair:  80\n",
      "model trained on image pair:  81\n",
      "model trained on image pair:  82\n",
      "model trained on image pair:  83\n",
      "model trained on image pair:  84\n",
      "model trained on image pair:  85\n",
      "model trained on image pair:  86\n",
      "model trained on image pair:  87\n",
      "model trained on image pair:  88\n",
      "model trained on image pair:  89\n",
      "model trained on image pair:  90\n",
      "model trained on image pair:  91\n",
      "model trained on image pair:  92\n",
      "model trained on image pair:  93\n",
      "model trained on image pair:  94\n",
      "model trained on image pair:  95\n",
      "model trained on image pair:  96\n",
      "model trained on image pair:  97\n",
      "model trained on image pair:  98\n",
      "model trained on image pair:  99\n",
      "model trained on image pair:  100\n"
     ]
    }
   ],
   "source": [
    "def train_svm(image_pairs, change_mask, kernel='rbf'):\n",
    "    model = SVC(kernel=kernel, probability=False)\n",
    "    h, w, _ = image_pairs[0][0].shape\n",
    "\n",
    "    for i in range(0, len(image_pairs)):\n",
    "      X_train, y_train = prepare_svm_data(image_pairs[i][0], image_pairs[i][1], change_mask[i])\n",
    "      model.fit(X_train, y_train)\n",
    "      print(f\"model trained on image pair: \", i+1)\n",
    "\n",
    "    return model, h, w\n",
    "\n",
    "\n",
    "svm_model, h, w = train_svm(image_pairs_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c974cdd",
   "metadata": {},
   "source": [
    "### Test SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349a6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested image pair: 1\n",
      "tested image pair: 2\n",
      "tested image pair: 3\n",
      "tested image pair: 4\n",
      "tested image pair: 5\n",
      "tested image pair: 6\n",
      "tested image pair: 7\n",
      "tested image pair: 8\n",
      "tested image pair: 9\n",
      "tested image pair: 10\n",
      "tested image pair: 11\n",
      "tested image pair: 12\n",
      "tested image pair: 13\n",
      "tested image pair: 14\n",
      "tested image pair: 15\n",
      "tested image pair: 16\n",
      "tested image pair: 17\n",
      "tested image pair: 18\n",
      "tested image pair: 19\n",
      "tested image pair: 20\n",
      "tested image pair: 21\n",
      "tested image pair: 22\n",
      "tested image pair: 23\n",
      "tested image pair: 24\n",
      "tested image pair: 25\n",
      "tested image pair: 26\n",
      "tested image pair: 27\n",
      "tested image pair: 28\n",
      "tested image pair: 29\n",
      "tested image pair: 30\n",
      "tested image pair: 31\n",
      "tested image pair: 32\n",
      "tested image pair: 33\n",
      "tested image pair: 34\n",
      "tested image pair: 35\n",
      "tested image pair: 36\n",
      "tested image pair: 37\n",
      "tested image pair: 38\n",
      "tested image pair: 39\n",
      "tested image pair: 40\n",
      "tested image pair: 41\n",
      "tested image pair: 42\n",
      "tested image pair: 43\n"
     ]
    }
   ],
   "source": [
    "def predict_svm_and_visualize(model, image_pairs, change_mask, h, w):\n",
    "    acc = 0\n",
    "    prec = 0\n",
    "    rec = 0\n",
    "    iou = 0\n",
    "    f1 = 0\n",
    "    for i in range(0, len(image_pairs)):\n",
    "        \n",
    "        X_test, y_true = prepare_svm_data(image_pairs[i][0], image_pairs[i][1], change_mask[i])\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"tested image pair: {i+1}\")\n",
    "\n",
    "        # change_map = y_pred.reshape(h, w)\n",
    "        # ground_truth = y_test.reshape(h, w)\n",
    "\n",
    "        # print(f\"Evaluating pair: \", i+1)\n",
    "        # print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # plt.figure(figsize=(12, 4))\n",
    "        # plt.subplot(1, 3, 1)\n",
    "        # plt.imshow(ground_truth, cmap='gray')\n",
    "        # plt.title(\"Ground Truth\")\n",
    "\n",
    "        # plt.subplot(1, 3, 2)\n",
    "        # plt.imshow(change_map, cmap='gray')\n",
    "        # plt.title(\"SVM Prediction\")\n",
    "\n",
    "        # plt.subplot(1, 3, 3)\n",
    "        # plt.imshow(ground_truth != change_map, cmap='Reds')\n",
    "        # plt.title(\"Error Map\")\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        acc += accuracy_score(y_true, y_pred)\n",
    "        prec += precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec += recall_score(y_true, y_pred, zero_division=0)\n",
    "        iou += jaccard_score(y_true, y_pred, zero_division=0)\n",
    "        f1 += f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "    acc = acc/len(image_pairs)\n",
    "    prec = prec/len(image_pairs)\n",
    "    rec = rec/len(image_pairs)\n",
    "    iou = iou/len(image_pairs)\n",
    "    f1 = f1/len(image_pairs)\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"IoU\": iou,\n",
    "        \"f1\": f1\n",
    "    }, y_pred, y_true\n",
    "\n",
    "\n",
    "metrics, y_pred, y_true = predict_svm_and_visualize(svm_model, image_pairs_test, labels_test, h, w)\n",
    "\n",
    "for name, value in metrics.items():\n",
    "    print(f\"{name}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CGNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
